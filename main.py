# main.py
from fastapi import FastAPI
from pydantic import BaseModel
from dotenv import load_dotenv
import os

# LangChain RAG ê´€ë ¨
from langchain.chains import RetrievalQA
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain_openai import ChatOpenAI  # Chat ëª¨ë¸ìš© ì˜¬ë°”ë¥¸ í´ë˜ìŠ¤

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")

# 1) FAISS ì¸ë±ìŠ¤ ë¡œë“œ (pickle ì—­ì§ë ¬í™” í—ˆìš©)
emb = OpenAIEmbeddings(openai_api_key=API_KEY)
vs = FAISS.load_local(
    "faiss_index",
    emb,
    allow_dangerous_deserialization=True
)

# 2) RetrievalQA ì²´ì¸ ì„¤ì •
qa_chain = RetrievalQA.from_chain_type(
    llm=ChatOpenAI(model_name="gpt-3.5-turbo", openai_api_key=API_KEY),
    chain_type="stuff",
    retriever=vs.as_retriever(search_kwargs={"k": 5}),
    return_source_documents=True
)

# FastAPI ì•± ë° ì—”ë“œí¬ì¸íŠ¸
app = FastAPI()

class ChatRequest(BaseModel):
    message: str

@app.post("/chat")
def chat(req: ChatRequest):
    result = qa_chain({"query": req.message})
    answer = result["result"]
    # ì¶œì²˜ ë¬¸ì„œ ëª©ë¡ ìƒì„±
    sources = sorted({doc.metadata.get("source") for doc in result["source_documents"]})
    citation_block = "\n".join(f"- {os.path.basename(src)}" for src in sources)
    return {
        "response": f"{answer}\n\nğŸ“‘ ì¶œì²˜ ë¬¸ì„œ:\n{citation_block}"
    }
