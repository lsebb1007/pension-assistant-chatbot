from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS
from fastapi import FastAPI, Query
from pydantic import BaseModel
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage, SystemMessage
import os
import pandas as pd
import re
from external_api import fetch_law_detail, fetch_dart_summary

load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")
app = FastAPI()
llm = ChatOpenAI(openai_api_key=openai_api_key, model="gpt-3.5-turbo")

# faiss_index ë²¡í„°DB ë¡œë“œ (ìµœì´ˆ 1íšŒë§Œ)
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
vectorstore = FAISS.load_local(
    "faiss_index", embeddings,
    allow_dangerous_deserialization=True
)



class ChatRequest(BaseModel):
    message: str
    session_id: str

# ì „ì—­ ëŒ€í™” ì„¸ì…˜ ì €ì¥ì†Œ
chat_sessions = {}

# ì±—ë´‡ ì‘ë‹µ API
@app.post("/chat")
def chat(request: ChatRequest):
    try:
        raw_text = request.message
        context_split = raw_text.split("[ì§ˆë¬¸]")
        if len(context_split) == 2:
            user_context, user_input = context_split
        else:
            user_context = ""
            user_input = raw_text

        session_id = request.session_id

        # ğŸ’¡ ë²¡í„°DBì—ì„œ ìœ ì‚¬ ê·¼ê±° ê²€ìƒ‰
        docs_and_scores = vectorstore.similarity_search_with_score(user_input, k=3)
        retrieved_context = "\n---\n".join([doc.page_content for doc, score in docs_and_scores])

        # ğŸ’¡ ìµœì¢… í”„ë¡¬í”„íŠ¸ í™•ì¥
        final_prompt = f"""{user_context.strip()}

[ê·¼ê±°]
{retrieved_context}

[ì§ˆë¬¸]
{user_input.strip()}
        """

        # íˆìŠ¤í† ë¦¬ ê´€ë¦¬
        if session_id not in chat_sessions:
            chat_sessions[session_id] = [
                SystemMessage(content="""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ê¸ˆìœµ ìƒë‹´ì„ ë„ì™€ì£¼ëŠ” AIì…ë‹ˆë‹¤. 'ë‚´', 'ì €', 'ë‚˜' ë“±ì€ ëª¨ë‘ ì‚¬ìš©ìë¥¼ ì§€ì¹­í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ [ê·¼ê±°] ë‚´ì—ì„œë§Œ ë‹µë³€í•˜ì„¸ìš”."""),
                HumanMessage(content=final_prompt)
            ]
        else:
            chat_sessions[session_id].append(HumanMessage(content=f"(ì°¸ê³ ) {final_prompt}"))

        chat_sessions[session_id].append(HumanMessage(content=user_input.strip()))
        response = llm(chat_sessions[session_id])
        chat_sessions[session_id].append(response)

        return {"response": response.content}

    except Exception as e:
        return {"response": f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}"}


@app.post("/fetch-law-detail")
def law_search(law_name: str = Query(...)):
    return fetch_law_detail(law_name)


@app.post("/fetch-dart-summary")
def dart_summary(corp_name: str = Query(...)):
    print(f"[ğŸ“¥ DART ìš”ì²­] corp_name: {corp_name}")
    result = fetch_dart_summary(corp_name)
    print(f"[ğŸ“¤ DART ì‘ë‹µ] {result}")
    return result